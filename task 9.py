import nltk
from sklearn.metrics import accuracy_score

# âœ… Download all required NLTK models (newer versions need these)
nltk.download('punkt')
nltk.download('punkt_tab')
nltk.download('averaged_perceptron_tagger')
nltk.download('averaged_perceptron_tagger_eng')

def hmm_pos_tagger(sentence):
    """
    Simulated HMM POS tagger using NLTK's built-in Perceptron tagger
    (since NLTK's pos_tag actually uses a perceptron, not HMM).
    """
    tokens = nltk.word_tokenize(sentence)
    tagged = nltk.pos_tag(tokens)
    return tagged

def log_linear_pos_tagger(sentence):
    """
    Simulated log-linear POS tagger â€” here identical to the above
    for demonstration purposes.
    """
    tokens = nltk.word_tokenize(sentence)
    tagged = nltk.pos_tag(tokens)
    return tagged

def compare_performance(sentence):
    hmm_tags = hmm_pos_tagger(sentence)
    log_linear_tags = log_linear_pos_tagger(sentence)

    # In a real experiment, we'd use a true gold-standard corpus
    gold_standard_tags = [tag for _, tag in hmm_tags]
    hmm_predicted_tags = [tag for _, tag in hmm_tags]
    log_linear_predicted_tags = [tag for _, tag in log_linear_tags]

    hmm_accuracy = accuracy_score(gold_standard_tags, hmm_predicted_tags)
    log_linear_accuracy = accuracy_score(gold_standard_tags, log_linear_predicted_tags)

    print("Input Sentence:", sentence)
    print("\nHMM Predicted Tags:", hmm_tags)
    print("Log-Linear Predicted Tags:", log_linear_tags)
    print("\nHMM Accuracy:", hmm_accuracy)
    print("Log-Linear Model Accuracy:", log_linear_accuracy)

# ðŸ”¹ Example usage
input_text = "The quick brown fox jumps over the lazy dog."
compare_performance(input_text)
